\documentclass[]{article}
\usepackage[margin = 1.5in]{geometry}
\setlength{\parindent}{0in}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{qtree}
\usepackage{float}
\usepackage[lined]{algorithm2e}
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}
\usepackage{color}
\usepackage{bussproofs}
\usepackage{enumerate}

\DeclarePairedDelimiter{\set}{\lbrace}{\rbrace}

\definecolor{darkish-blue}{RGB}{25,103,185}

\hypersetup{
    colorlinks,
    citecolor=darkish-blue,
    filecolor=darkish-blue,
    linkcolor=darkish-blue,
    urlcolor=darkish-blue
}

\theoremstyle{definition}
\newtheorem*{defn}{Definition}
\newtheorem*{theorem}{Theorem}
\newtheorem*{corollary}{Corollary}
\newtheorem*{aside}{Aside}
\newtheorem{ex}{Example}[section]

\crefname{ex}{Example}{Example}

\setlength{\marginparwidth}{1.5in}
\newcommand{\lecture}[1]{\marginpar{{\footnotesize $\leftarrow$ \underline{#1}}}}

\stepcounter{footnote} % because daggers are cool

\begin{document}
	\let\ref\Cref

	\title{\bf{CS 360: Introduction to the Theory of Computing}}
	\author{Professor Shai Ben-David \\ \\ Fall 2013, University of Waterloo}
  \date{Notes taken by Chris Thomson\thanks{See \href{http://cthomson.ca/notes}{cthomson.ca/notes}.
	\ifdefined\sha % Also, \commitDateTime should be defined.
		Last modified: \commitDateTime{} ({\href{https://github.com/christhomson/lecture-notes/commit/\sha}{\sha}}).
	\fi}}

	\maketitle

	\section{Introduction \& Course Structure} \lecture{September 10, 2013}
    \subsection{Course Structure}
      The grading scheme is 30\% assignments, 30\% midterm, and 40\% final. If your final grade is better than your midterm grade, your final will be worth 70\% and the midterm will be worth 0\%.
      \\ \\
      In terms of textbooks, any textbook relating to ``automata theory'', ``theory of computation'', or ``formal language theory'' is acceptable.
      \\ \\
      The professor's office is in DC 1311, and his office hours are on Tuesdays from 2:00 to 3:00 pm.
      \\ \\
      This course is mathematical. Consequently, relevant background courses are mainly mathematical (mostly logic) and  (almost) no programming.

    \subsection{Introduction}
      The goal of the course is to develop the theory of computation. We want to understand the mathematics that govern computers. We will explore questions like:
      \begin{itemize}
        \item What are computers?
        \item Which tasks can computers carry out?
        \item Which tasks are easy or hard for computers?
      \end{itemize}

      We make abstractions and use them as common properties that are relevant to many phenomenon. We aren't going to be focussing on any particular programming language or machine architecture, but instead, we'll focus on issues that underlie any automated computation.
      \\ \\
      These abstractions allow us to form conclusions that are relevant to computing in general, and not just for today's hardware and software.
      \\ \\
      This course has two key goals:
      \begin{enumerate}
        \item To familiarize you with the fundamentals of computer science theory.
        \item To develop the ability to reason formally and abstractly about computing.
      \end{enumerate}

    Throughout the course, we will follow two main threads concurrently: abstract models of computers, and computing tasks. We'll progress from simple models and simple tasks to complex models and complex tasks, and along the way connections will be made between the two.

    \subsection{Computing Tasks}
      We're going to focus on \textbf{decision problems}. Decisions problems are problems which have an input and produce a binary (yes/no) output. Some examples of decision problems are:
      \begin{itemize}
        \item Input: a number. Decision: is it a prime number?
        \item Input: email message. Decision: is it spam?
        \item Input: a graph. Decision: is it connected?
      \end{itemize}

      We're interested in seeing which of these questions a computer can carry out and how difficult are such task.

      \subsubsection{Modelling Decision Problems}
        We model decision problems using \textbf{formal languages}. A decision problem has two components:
        \begin{itemize}
          \item A domain set $X$.
          \item A language $L \subseteq X$.
        \end{itemize}

        Our decision problem is then ``for some $x \in X$, is $x \in L$?'' Re-examining our examples from earlier, we would define:
        \begin{itemize}
          \item $X = \mathbb{Z}$ (the set of all integers), and $L = $ the set of all prime numbers.
          \item $X = $ the set of all email messages, and $L = $ the set of all spam email messages.
          \item $X = $ the set of all graphs, and $L = $ the set of all connected graphs.
        \end{itemize}

        For further concreteness, we will fix some finite set $\Sigma$, which we will call the \textbf{alphabet}. Some examples of alphabets are $\set{a, b}$, $\set{0, 1}$, and $\set{0, 1, 2, 3}$.
        \\ \\
        $\Sigma^\star$ represents the set of all finite strings over the alphabet $\Sigma$. In many cases, we define $X = \Sigma^\star$. For example, if $\Sigma = \set{0, 1}$ then $\Sigma^\star = \set{ \epsilon, 0, 1, 00, 11, 01, 10, \ldots }$. Note that $\Sigma^\star$ is an infinite set, but every member of $\Sigma^\star$ is finite.
        \\ \\
        For the time being, we will define just one operation for strings, : \textbf{concatenation}. Given two strings, $\sigma$ and $\eta$, we get $\sigma \eta$. That is,
          \AxiomC{$\sigma$}
          \AxiomC{$\eta$}
          \BinaryInfC{$\sigma \eta$}
          \DisplayProof . For example, if $\sigma = 01$ and $\eta = 111$, then $\sigma \eta$ is 01111.
        \\ \\
        \textbf{Languages} are subsets of $\Sigma^\star$ (that is, a language is a collection of strings). Some examples of languages include:
        \begin{itemize}
          \item $L = \emptyset$. This is the \textbf{empty language}, which no strings belong to. Note that $|L| = 0$. This is analogous to an empty fridge.
          \item $L = \set{ \epsilon }$. This is a non-empty language that contains one element ($|L| = 1$), which just happens to be $\epsilon$. This is analogous to having a fridge that contains only an empty can.
          \item $L = \set{\epsilon, 0, 01, 11111}$.
          \item $L = \Sigma^\star$.
        \end{itemize}

        Compilers task of checking their input (the code of a program) to see if the program is valid (if the code is in the language), can be readily seen as checking membership in such a language (namely, the language of all binary sequences that represent a valid code in the given programming language).
        \\ \\
        %We will discuss tasks that help us determine if a particular string belongs to a particular language or not.

  \section{Inductive definition of sets and Structural Induction (CS 245 Review)}
    We'll start off by reviewing some basic notions that were covered on CS 245, to ensure that everyone's on the same page.
      \subsection{Formal Tools for Defining Sets}
        We want languages to model every computational task, some of which are complex. We need several different methods for formally defining sets, since all languages are sets.

        \begin{enumerate}
          \item \textbf{List all members of the set}. This method is precise and concrete, but it makes look-ups difficult ($O(n)$) and it fails if the set is infinitely large.
          \item \textbf{Common property that characterizes the members of the set}. For example, consider the set of all even numbers. This set is not definable by a list because it's an infinite set. However, there is a common property that's shared between all members of the set: if you divide by two and examine the remainder, every member in the set will have a remainder of zero and only members of the set have this property.
          \item \textbf{Inductive definitions}. Methods (1) and (2) don't offer us a way to define a set of all your blood relatives, since there's no property that characterizes that set. Instead, we could use \emph{inductive definitions}.
          \\ \\
          Inductive definitions of sets requires three components:
          \begin{itemize}
            \item A domain set $X$ (sometimes omitted if it is obvious).
            \item A core set $A$ (as in ``atoms''), such as $\set{ \text{me} }$.
            \item A set of operations $P$, such as $\set{ \text{``son of''}, \text{``father of''}, \text{``mother of''}}$. This set is a set of functions from $X \to X$.
          \end{itemize}

          Given these components, we define the \textbf{inductive set} $I(A, P)$, (say, the set of blood relatives), as all domain elements that can be reached from the core set by applying a finite sequence of operations.
          \\ \\
          More formally,  $I(A, P)$ - the inductive set defined by core $A$ and operations $P$ - is the smallest set satisfying:
          \begin{itemize}
            \item Contains all members of $A$, and
            \item Closed under the operations in $P$.
          \end{itemize}

          \noindent \textbf{Examples:}
          \begin{itemize}
          \item Let the domain be the set of all real numbers, the core set be $\set{2}$, and the set of operations be $\set{ \text{``add 2''}, \text{``subtract 2''}}$. The defined set is the set of all even numbers, both positive and negative.

          \item To define the set of all algebraic expressions. Our core set would be $\set{x, y, z, 1, 2, 3, \ldots, a, b, c, \ldots}$. Our operations would be:
          \AxiomC{$\sigma$} \AxiomC{$\eta$} \BinaryInfC{$(\sigma + \eta)$} \DisplayProof,\AxiomC{$\sigma$} \AxiomC{$\eta$} \BinaryInfC{$(\sigma \cdot \eta)$} \DisplayProof.
          \end{itemize}
          Given a set (language) defined inductively, how can we tell if some $x \in X$ is in the language or not?
          %We must provide a particular sequence of operations necessary to produce that $x$.

          \begin{ex}
            \label{strConcatenationExample}
            Let $X = \set{a, b}^\star$, $A = \set{a}$, and $P = $ \bigg\{ \AxiomC{X} \UnaryInfC{aX} \DisplayProof, \AxiomC{X} \UnaryInfC{Xa} \DisplayProof, \AxiomC{X} \AxiomC{Y} \BinaryInfC{bXY} \DisplayProof, \AxiomC{X} \AxiomC{Y} \BinaryInfC{XbY} \DisplayProof, \AxiomC{X} \AxiomC{Y} \BinaryInfC{XYb} \DisplayProof \bigg\}.
            \\ \\
            A typical question would be: is $abbaa \stackrel{?}{\in} I(A, P)$? The answer: yes! However, we must show how to generate $abbaa$ from $a$, using the operations in $P$, in a finite number of steps.

            \begin{enumerate}[1.]
            \item $a$, belongs to the core $A$.
            \item $baa$, after applying $P_3(a, a)$.
            \item $abbaa$, after applying $P_4(a, baa)$.
            \end{enumerate}

            Note that the first step must always be an element in the core set.
            \\ \\
            Is $\epsilon \in I(A, P)$? No. We could use simple reasoning to show that $\epsilon \not \in I(A, P)$ (each function in $P$ increases the length). However, in general, it is more difficult to prove non-membership of an element than it is to prove membership of another element.
          \end{ex}

          A \textbf{certificate} (or \textbf{generating sequence}) for $x$ is a sequence of elements of $X, \theta_1, \theta_2, \theta_3, \ldots, \theta_n$ such that:
          \begin{itemize}
            \item $\theta_n = x$, and
            \item Every $\theta_i$ in the sequence is either an element of the core set $A$ or is the result of applying an operation from $P$ to a $\theta_j, \theta_l$ that appeared earlier in the sequence ($j < i$ and $l < i$). \lecture{September 12, 2013}
          \end{itemize}
        \end{enumerate}

        Our definition of $I(A, P)$ is still somewhat informal, however. We haven't formally defined what it means for a subset to be the \emph{smallest} subset, and we also haven't formally defined what it means for a set to be ``closed'' under a set of operations.

        \subsection{More on Inductive Sets and Structural Induction}
        More formally, we say that a set $B$ is \textbf{closed under the operations of $\boldsymbol P$} if for every $f \in P$ and every $x, y \in B$, $f(x, y) \in B$ (for concreteness, we considered here an $f$ that accepts two inputs, but it may also be a unary function, $f(x)$ or ternary $f(x,y, z)$ etc.). For example, the set of even numbers is closed under the operation +.
        \\ \\
        Now, let's redefine $I(A, P)$ in a more formal way:
        $$
          I(A, P) = \bigcap \left\{ B : A \subseteq B ~\text{ and } ~B ~\text{ is closed under } ~P \right\}
        $$

        Note that $I(A, P)$ is the intersection over the \emph{entire} collection of sets (and is therefore uniquely defined).

        \begin{ex}
          Let $X = \mathbb{N}, A = \set{10}, P = \set{+}$.
          \\ \\
          $I(A, P)$ is defined as the intersection of all sets $B$ such that $ A \subseteq B $ and $B$ is closed under $P$ (that is, $B$ is closed under $+$). So, we have:
          \begin{itemize}
            \item $B_1 = \set{\text{all even numbers}}$
            \item $B_2 = \set{\text{all numbers divisible by 5}}$
            \item $B_3 = \set{\text{all numbers divisible by 10}}$
          \end{itemize}

          In this case, $I(A, P) = \set{10, 20, 30, \ldots}$, since $I(A, P)$ must be the minimal set among all possible sets $B$ (or, in other words, the multiples of 10 are exactly the numbers that belong to each and every of these sets $B$).
        \end{ex}

        \begin{aside}
          \begin{align*}
            \bigcap \left\{ [0, r] : r > 0 \right\} &= \set{0} \\
            \bigcap \left\{ (0, r) : r > 0 \right\} &= \emptyset \\
            \bigcup \left\{ \set{1, \ldots, n} : n \in \mathbb{N} \right\} &= \mathbb{N} \\
            \bigcap \left\{ \set{1, \ldots, n} : n \in \mathbb{N} \right\} &= \set{1}
          \end{align*}
        \end{aside}

        The equivalence of the two definitions of $I(A, P)$ is not immediately clear. We claim that $I(A, P)$ is closed under the operations of $P$, and $A \subseteq I(A, P)$.

        \begin{proof}
          Pick any $x, y \in I(A, P)$ and operation $f \in P$. For every $B$ which contains $A$ and is closed under $P$, $x, y \in B$ (since $I(A,P)$ is the intersection of all such $B$'s).
          \\ \\
          Since every such $B$ is closed under $P$, $f(x, y) \in B$ for every such $B$. Therefore, $f(x, y) \in \cap \set{ B : A \subseteq B \text{ and } B \text{ is closed under } P}$, so $f(x,y) \in I(A, P)$.
          \\ \\
          \underline{Exercise}: prove that $A \subseteq I(A, P)$.
        \end{proof}

        \begin{corollary}[Proof by Structural Induction Theory]
          Any $B \subseteq X$ which contains $A$ and is closed under $P$ is a superset of $I(A, P)$. Namely, $I(A, P) \subseteq B$.
        \end{corollary}

        We could rephrase this corollary as follows: given any set $B$, if you want to prove that $I(A, P) \subseteq B$, it suffices to show:
        \begin{itemize}
          \item $A \subseteq B$, and
          \item $B$ is closed under $P$.
        \end{itemize}

      \subsubsection{Proof by Structural Induction}
        Let's say we want to show that for every $n$, $n^2 + n$ is even. A proof by usual (mathematical) induction requires us to show two things:
        \begin{itemize}
          \item Prove the claim holds for $n = 1$. This is equivalent to showing that $A \subseteq B$.
          \item Prove that if the claim holds for $n$, it also holds for $n + 1$. This is equivalent to showing that $B$ is closed under $P$.
        \end{itemize}

        How is this the same as structural induction? Usual induction shows that $\mathbb{N} = I(A, P)$, where $A = \set{1}$ and $P = \set{ \text{``+1''}}$. That is, mathematical induction is just one specific case of structural induction.

      \subsection{Examples of Proofs by Structural Induction}
        \begin{ex}
          Imagine we have three paper cups placed on a desk, with two of them facing upwards and one upside down. You must flip exactly two cups at a time. We want to get all of the cups facing upwards. Can we prove that this goal is not achievable?
          \\ \\
          Let $X$ be the set of all possible configurations of the cups. Let our core set $A$ contain only the state ``[up] [down] [up]''. Let our set of operations $P$ contain:
          \begin{itemize}
            \item $P_1$: flip the two rightmost cups.
            \item $P_2$: flip the two leftmost cups.
            \item $P_3$: flip the rightmost and leftmost cups.
          \end{itemize}

          We claim that the state ``[up] [up] [up]'' $\not \in I(A, P)$.
          \begin{proof}
            Let $B$ be the set of all configurations with an even number of ``up'' cups.
            \\ \\
            We want to show that $I(A, P) \subseteq B$. This would show that ``[up] [up] [up]'' is not attainable because it is not a member of $B$. We will use structural induction to show this.
            \\ \\
            \textbf{Induction base}: $A \subseteq B$.
            \\ \\
            \textbf{Induction step}: $B$ is closed under $P$. Namely, if $c \in B$, then $P_1(c), P_2(c)$, and $P_3(c) \in B$. There are three cases:
            \begin{itemize}
              \item We flip one ``up'' cup and one ``down'' cup. This is a difference of +0 ``up'' cups.
              \item We flip two ``up'' cups. This causes us to remove two (which is even) from an already even number, which gives us another even number of ``up'' cups.
              \item We flip two ``down'' cups. This causes us to add two (which is even) to an already even number, which gives us another even number of ``up'' cups.
            \end{itemize}

            Note that these three cases show us that no matter which operation we use, it is not possible to obtain all three ``up'' cups, since the number of ``up'' cups will always be even.
          \end{proof}
        \end{ex}

        \begin{ex}
          Recall in \ref{strConcatenationExample} we defined $X = \set{a, b}^\star$, $A = \set{a}$, and $P = $ \bigg\{ \AxiomC{X} \UnaryInfC{aX} \DisplayProof, \AxiomC{X} \UnaryInfC{Xa} \DisplayProof, \AxiomC{X} \AxiomC{Y} \BinaryInfC{bXY} \DisplayProof, \AxiomC{X} \AxiomC{Y} \BinaryInfC{XbY} \DisplayProof, \AxiomC{X} \AxiomC{Y} \BinaryInfC{XYb} \DisplayProof \bigg\}.
          \\ \\
          For this example, let $\#_a(x)$ denote the number of ``a''s in the string $x$ and similarly, let $\#_b(x)$ denote the number of ``b''s in the string $x$.
          \\ \\
          \textbf{Claim}: every member of $I(A, P)$ has more ``a''s than ``b''s. To put this more simply, let $B = \set{ x : \#_a(x) > \#_b(x) }$. We wish to show that $I(A, P) \subseteq B$.
          \begin{proof}
            We will prove this claim by structural induction.
            \\ \\
            \textbf{Induction base}: $A \subseteq B$. It is trivial to see that the string ``a'' has more ``a''s than ``b''s (since it has no ``b''s).
            \\ \\
            \textbf{Induction step}: if $x, y \in B$, then we must show that $P_1(x) \in B, P_2(x) \in B, P_3(x, y) \in B, P_4(x,y) \in B$, and $P_5(x, y) \in B$.
            \\ \\
            It is clear that for $P_1$ and $P_2$, one ``a'' is being added to a string that must already include more ``a''s than ``b''s, so this trivially holds true.
            \\ \\
            The case of $P_3$ isn't as immediately obvious. Assume $\#_a(x) > \#_b(x)$, and $\#_a(y) > \#_b(y)$. So, $\#_a(x) \ge \#_b(x) + 1$ and $\#a(y) \ge \#_b(y) + 1$. This gives us $\#_a(xy) \ge \#_b(xy) + 2$.
            \\ \\
            Now, note that $\#_a(bxy) = \#_a(xy)$, and $\#_b(bxy) = \#_b(xy) + 1$. We can conclude that $\#_a(bxy) \ge \#_b(bxy) + 1 > \#_b(bxy)$.
            \\ \\
            A similar argument applies for $P_4$ and $P_5$.
          \end{proof}
        \end{ex}

      \subsection{Regular Languages}
        For us, tasks will always be decision problems. That is, given $L \subseteq \set{a, b}^\star$ and input $x \in \set{a, b}^\star$, decide if $x \in L$.
        \\ \\
        The set of all possible tasks is $\set{L : L \subseteq \set{a, b}^\star}$. This set is an infinite set of finite strings.
        \\ \\
        Recall that not all infinite sets have the same size. The set of all finite strings $\set{a, b}^\star$ is a ``small'' infinite set, meaning it is \textbf{countable}. However, the set of all subsets of $\set{a, b}^\star$ is a ``large'' infinite set, which is \textbf{uncountable}.
        \\ \\
        The set of all possible computer programs is a subset of $\set{0, 1}^\star$. Note that since every program is a \emph{finite} string, the set of all possible programs is countable.
        \\ \\
        In summary, we have an uncountable number of tasks, but a countable number of programs (and each program is suitable for carrying out at most a single task). This implies that there are tasks (languages) for which no program exists (namely, for such languages, $L$, there exists no program that will figure out correctly for every string $x$ whether it is a member of $L$ or not).

      \subsection{Defining Interesting Families of Tasks} \lecture{September 17, 2013}
        \begin{aside}
          The empty string can be denoted as either $\epsilon$ or $\lambda$.
        \end{aside}

        \subsubsection{Operations on Languages}
          There are several operations that we can perform on languages.
          \\ \\
          We can use \textbf{standard set operations}, including $\bigcup, \bigcap$, complement ($\overline A$), and set difference ($A \textbackslash B$). You should be familiar with how these standard operations are defined.
          \\ \\
          Since we focus on subsets of the set of finite strings, $\Sigma^\star$, we can also use \textbf{operations on sets of such strings}. Let's go into more detail of how these string set operations are defined.

          \begin{enumerate}
            \item \textbf{The concatenation operation}. Given $L_1, L_2 \subseteq \Sigma^\star$, we define $L_1 L_2 = \set{ w_1 w_2 : w_1 \in L_1, w_2 \in L_2 }$.

            \begin{ex}
            Let $L_1 = \set{0, 011}$ and $L_2 = \set{ \epsilon, 110 }$. Then $L_1 L_2 = \set{0, 0110, 011, 011110 }$.
            \end{ex}

            Concatentation is not always commutative. Consider $L_1 = \set{0}$ and $L_2 = \set{1}$. We have $L_1 L_2 = \set{01}$ but $L_2 L_1 = \set{10}$, so $L_1 L_2 \ne L_2 L_1$.
            \\ \\
            Can $L_1 \subseteq L_1 L_2$? Yes, but only if $\epsilon \in L_2$. Otherwise, $L_1 \not \subseteq L_1 L_2$.

            \item \textbf{The power operation}. Given any language $L$, define:
              \begin{itemize}
                \item $L^0 = \set{ \epsilon }$
                \item $L^{n + 1} = L^n L$ for every $n > 0$
              \end{itemize}

              In particular, note that $L^1 = \set{ \epsilon} L = L$.

              \begin{ex}
                Let $L = \set{ 0, 1 }$. Then $L^n$ is the set of all ($\set{0, 1}$) strings.
              \end{ex}

            \item \textbf{The star (Kleene) operation}. For any language $L$, $L^\star = \displaystyle \bigcup_n L^n$. That is, $L^\star$ is the set of all finite concatenations of strings from $L$. Note that $L^\star$ includes $L^0$, which means $\epsilon \in L^\star$.
          \end{enumerate}

          \noindent \textbf{Examples:}
            \begin{itemize}
              \item $\set{1}^\star$ is the set of all finite strings of 1s.
              \item $\set{0, 1}^\star$ is the set of all finite $\set{0, 1}$ strings.
              \item Can $L^\star = L$? Yes. Consider $L = \set{ \epsilon }$, or $(L^\star)^\star = L^\star$ for any $L$.
              \item Can $L^\star$ be finite? Yes. Consider $L = \set{ \epsilon }$ or $L = \emptyset$.
            \end{itemize}

        \subsubsection{The Set of Regular Languages}
          Given some finite alphabet set $\Sigma$, let $X = \Sigma^\star$. We will also define our core set to be:
          $$
            A = \set{\emptyset, \set{\epsilon}} \cup \set{ \set{a} : a \in \Sigma }
          $$

          For instance, suppose $\Sigma = \set{0, 1}$. Then $A = \set{ \emptyset, \set{ \epsilon }, \set{ 0 }, \set{ 1 } }$. Finally, we'll define our set of operations $P$:
          $$
            P = \text{ \bigg\{ \AxiomC{$L_1$} \AxiomC{$L_2$} \BinaryInfC{$L_1 \cup L_2$} \DisplayProof, \AxiomC{$L_1$} \AxiomC{$L_2$} \BinaryInfC{$L_1 \cdot L_2$} \DisplayProof, \AxiomC{$L$} \UnaryInfC{$L^\star$} \DisplayProof \bigg\}}
          $$

          A language is said to be \textbf{regular} if it belongs to $I(A, P)$, for this $A$ and $P$.
          \\ \\
          To prove a language is regular, you must be able to show how to generate it.

          \begin{ex}
            $\set{0, 1, 01}$ is regular.
            \begin{proof}
              \begin{align}
                \set{0} &\text{ core} \\
                \set{1} &\text{ core} \\
                \set{01} &\text{ product} \\
                \set{0, 1} &\text{ union of (1) and (2)} \\
                \set{0, 1, 01} &\text{ union of (3) and (4)}
              \end{align}
            \end{proof}
          \end{ex}

          \textbf{Claim 1}: for every (finite) string $\sigma$, $\set{\sigma}$ is a regular language. It's easy to see this is true, because you can generate the language by concatenating the languages that represent individual letters.
          \\ \\
          \textbf{Claim 2}: every finite language is regular. Since we know every $\set{\sigma}$ is regular, so is a finite unions of such.

          \begin{ex}
            Let $L_\text{even}$ be the language of all words of even length. $L_\text{even}$ is regular. We can form every word in $L_\text{even}$ using the expression $(\set{0, 1} \set{0, 1})^\star$.
          \end{ex}

          \begin{ex}
            Let $L_\text{equal} = \set{ w : \#_0(w) = \#_1(w) }$. $L_\text{equal}$ is not regular. We can't prove this yet though.
          \end{ex}

      \subsection{Explicit Descriptions of Regular Languages: Regular Expressions}
        A \textbf{regular expression} is just a word in a language that is designed to describe languages.

        \subsubsection{Defining The Set of Regular Expressions}
          Given some alphabet $\Sigma$, let $X$ be defined as
          $$
            X = (\Sigma \cup \set{+, \star, (, ), \emptyset, \epsilon})^\star
          $$

          We will define our core set $A$ as
          $$
            A = \set{\emptyset, \epsilon} \cup \set{ a : a \in \Sigma }
          $$

          Finally, we will define our set of operations $P$ as
          $$
            P = \left\{ \text{\AxiomC{$r_1$} \AxiomC{$r_2$} \BinaryInfC{$r_1 + r_2$} \DisplayProof, \AxiomC{$r_1$} \AxiomC{$r_2$} \BinaryInfC{$r_1 r_2$} \DisplayProof, \AxiomC{$r$} \UnaryInfC{$r^\star$} \DisplayProof, \AxiomC{$r$} \UnaryInfC{$(r)$} \DisplayProof } \right\}
          $$

          A regular expression is any member of this $I(A, P)$.
          \\ \\
          Suppose $\Sigma = \set{a, b}$. Some regular expressions over $\Sigma$ are $a$, $ab$, $a + b$, $a(a + \epsilon)^\star$, and $(a + b)(a + b)$.
          \\ \\
          \textbf{Claim}: in any regular expression, the number of $+$ symbols is at least one less than the number of symbols from the set $\Sigma \cup \set{ \epsilon, \emptyset }$. The proof of this (by structural induction) is left as an exercise.

        \subsubsection{Mapping Regular Expressions to Languages}
          We will define a mapping $L$ such that $L: \text{Regular Expression} \to \text{Language}$. We define such a mapping $L$ recursively over the definition of regular expressions.

          \begin{itemize}
            \item $L(\epsilon) = \set{ \epsilon }$
            \item $L(a) = \set{ a }$ for every $a \in \Sigma$
          \end{itemize}

          Assume $L(r_1)$ and $L(r_2)$ are already defined. We then define the mappings for each operation:
          \begin{itemize}
            \item $L(r_1 r_2) = L(r_1) L(r_2)$
            \item $L(r_1 + r_2) = L(r_1) \cup L(r_2)$
            \item $L(r_1^\star) = (L(r_1))^\star$
            \item $L((r_1)) = L(r_1)$
          \end{itemize}

          \noindent \textbf{Examples}:
          \begin{itemize}
            \item Let $r = (0 + 1)$. Then $L(r) = \set{0, 1}$.
            \item Let $r = 01$. Then $L(r) = \set{01}$.
            \item Let $r = (01)^\star$. Then $L(r) = \set{ \epsilon, 01, 010101, 01\ldots0101\ldots01, \ldots}$.
            \item Let $r = (01)^\star + (10)^\star$. Then $L(r)$ is the set of all alternating strings that either start with 0 and end with 1, or start with 1 and end with 0.
          \end{itemize}

          Find an expression $r$ such that $L(r)$ is the set of \emph{all} alternating strings. One such expression is $r = (0 + \epsilon)(10)^\star(1 + \epsilon)$. Another expression to represent the same language is $r' = (01)^\star + (10)^\star + 1(01)^\star + 0(10)^\star$.
          \\ \\
          Since $L(r) = L(r')$ represent the same language, this shows that there is no \emph{unique} regular expression to describe a language. Multiple distinct regular expressions can represent the same language.

        \subsubsection{Uses of Regular Expressions}
          Regular expressions are often useful to search for patterns in code. For example, if you were looking for all strings that start with ``a'' and end with ``b'', you could use the regular expression $a(a + b)^\star b$.
          \\ \\
          Regular expressions are also used in compilers. Compilers need to find certain patterns in the code they're given to compile, in order to perform the parsing step of the compilation.
          \\ \lecture{September 19, 2013} \\
        \emph{The lecture from September 19, 2013 is omitted. If you have notes from this lecture, feel free to email me (\href{mailto:chris@cthomson.ca}{chris@cthomson.ca}) and I'll include them here.}

  \section{Computing Machines} \lecture{September 24, 2013}
    \subsection{Deterministic Finite Automata}
      The first model of computing machines that we'll discuss are \textbf{deterministic finite automata} (also known as \text{DFA}s). A DFA is denoted by $A = (\Sigma, Q, q_0, \delta, F)$, where
      \begin{itemize}
        \item $\Sigma$ is the alphabet (the set of letters) of the DFA.
        \item $Q$ is the set of all states in the DFA.
        \item $q_0$ is the initial state.
        \item $\delta$ is the transition function.
        \item $F$ is a set of accepting states. (Note that there can be more than one accepting state.)
      \end{itemize}

      Every DFA can be represented with a bubble diagram, to make it easier to visualize.
      \begin{ex}
        A bubble diagram that represents the DFA that accepts all strings with an even number of $0$s and an odd number of $1$s is as follows:

        % http://madebyevan.com/fsm/ is a great tool for generating these.
        % It generates somewhat verbose code, unfortunately.
        \begin{center}
          \begin{tikzpicture}[scale=0.2]
          \tikzstyle{every node}+=[inner sep=0pt]
          \draw [black] (11.1,-17.2) circle (3);
          \draw (11.1,-17.2) node {$q_0$};
          \draw [black] (38.2,-14.3) circle (3);
          \draw (38.2,-14.3) node {$q_1$};
          \draw [black] (38.2,-14.3) circle (2.4);
          \draw [black] (55.8,-13.6) circle (3);
          \draw (55.8,-13.6) node {$q_2$};
          \draw [black] (27.5,-32.2) circle (3);
          \draw (27.5,-32.2) node {$q_3$};
          \draw [black] (13.215,-15.077) arc (130.7768:61.43928:19.862);
          \fill [black] (35.68,-12.67) -- (35.22,-11.85) -- (34.74,-12.73);
          \draw (23.86,-9.78) node [above] {$1$};
          \draw [black] (35.507,-15.62) arc (-66.28802:-101.4959:35.741);
          \fill [black] (14.01,-17.92) -- (14.7,-18.57) -- (14.89,-17.59);
          \draw (25.15,-19.02) node [below] {$1$};
          \draw [black] (24.505,-32.212) arc (-95.55965:-169.33456:14.845);
          \fill [black] (24.51,-32.21) -- (23.76,-31.64) -- (23.66,-32.63);
          \draw (14.91,-28.88) node [below] {$0$};
          \draw [black] (52.963,-14.571) arc (-74.43247:-101.01232:25.813);
          \fill [black] (52.96,-14.57) -- (52.06,-14.3) -- (52.33,-15.27);
          \draw (47.09,-16.04) node [below] {$0$};
          \draw [black] (54.064,-16.046) arc (-37.38097:-75.98969:42.768);
          \fill [black] (30.43,-31.58) -- (31.33,-31.87) -- (31.09,-30.9);
          \draw (44.57,-26.32) node [below] {$1$};
          \draw [black] (55.342,-16.562) arc (-12.78146:-100.5892:21.52);
          \fill [black] (55.34,-16.56) -- (54.68,-17.23) -- (55.65,-17.45);
          \draw (47.18,-30.28) node [below] {$1$};
          \draw [black] (40.512,-12.399) arc (122.65769:61.89753:12.697);
          \fill [black] (40.51,-12.4) -- (41.46,-12.39) -- (40.92,-11.55);
          \draw (46.83,-9.86) node [above] {$0$};
          \draw [black] (13.954,-18.118) arc (68.51255:26.59325:23.447);
          \fill [black] (13.95,-18.12) -- (14.52,-18.88) -- (14.88,-17.95);
          \draw (22.2,-22.15) node [above] {$0$};
          \end{tikzpicture}
        \end{center}
      \end{ex}

      To define $L(A)$, we extend $\delta: Q \times \Sigma \to Q$, to: $\hat{\delta}: Q \times \Sigma^\star \to Q$. Now, we define the language accepted by DFA $A$ as:
      $$
        L(A) = \set{ w : \hat{\sigma}(q_0, w) \in F }
      $$

      \textbf{Claim}: or this automata, $L(A) = \set{ w : \#_0(w) \text{ is even, and } \#_1(w) \text{ is odd }}$. But how do we prove this?
      \\ \\
      Let's rephrase our claim. For every $w \in \set{0, 1}^\star$, if $\#_0(w)$ is even and the $\#_1(w)$ is odd, then $A$ accepts $w$, and otherwise, $A$ does not accept $w$.
      \\ \\
      Since we said ``for every $w \in \set{0, 1}^\star$'', that should be a giveaway that we should use structual induction for this proof.
      \\ \\
      Let's define $\set{0, 1}^\star$ inductively. Note that we are \emph{not} yet defining the set of accepted members for the DFA, but instead, we are aiming to inductively define the set of all possible words across the alphabet $\Sigma = \set{0, 1}$.
      \\ \\
      We have our core set $A = \set{ \epsilon }$ (not to be confused with the $A$ we're using to denote the DFA). We also have two operations for any string $\sigma$,
      $$
        P = \bigg\{ \text{\AxiomC{$\sigma$} \UnaryInfC{$\sigma 1$} \DisplayProof, \AxiomC{$\sigma$} \UnaryInfC{$\sigma 0$} \DisplayProof} \bigg\}
      $$

      Rather than proving our claim directly, it will be easier to prove a stronger claim, which characterizes every state of the machine. This stronger claim (four claims, in fact) will be easier to prove because we'll have more to work with in our induction hypothesis.
      \\ \\
      For every $w \in \set{0, 1}^\star$:

      \begin{itemize}
        \item If $\#_0(w)$ is even and $\#_1(w)$ is even, then $\hat{\delta}(q_0, w) = q_0$.
        \item If $\#_0(w)$ is even and $\#_1(w)$ is odd, then $\hat{\delta}(q_0, w) = q_1$.
        \item If $\#_0(w)$ is odd and $\#_1(w)$ is odd, then $\hat{\delta}(q_0, w) = q_2$.
        \item If $\#_0(w)$ is odd and $\#_1(w)$ is even, then $\hat{\delta}(q_0, w) = q_3$.
      \end{itemize}

      \begin{proof}
        We will prove the four claims using structural induction on $\set{0, 1}^\star$.
        \\ \\
        \textbf{Base case}: $w = \epsilon$. It's easy to see that $\#_0(w)$ is even, $\#_1(w)$ is even, and indeed, $\hat{\delta}(q_0, \epsilon) = q_0$.
        \\ \\
        \textbf{Induction step}: assume the four claims hold for $w$. We need to show they hold for $w_0$ and $w_1$.
        \\ \\
        \underline{The operation $w_0$}: if $\#_0(w_0)$ is even and $\#_1(w_0)$ is even, then $\#_0(w)$ is odd and $\#_1(w)$ is even. By the induction hypothesis, $\hat{\delta}{q_0, w} = q_3$.
        \\ \\
        By the definition of $\hat{\delta}$, $\hat{\delta}(q_0, w_0) = \delta( \hat{\delta}(q_0, w), 0) = \delta(q_3, 0) = q_0$.
        \\ \\
        In order to finish this proof, we still need to prove the other three cases for $w_0$ and all four cases for $w_1$.
      \end{proof}

      Every task carried out by a DFA $A$ has the general form: ``given some input string $w$, decide if $w \in L(A)$''. In particular, we can say each $A$ handles the decision problem of the language $L(A)$. DFAs perform this task by consuming one character of $w$ at a time.
      \\ \\
      Note that not every language can be represented by a DFA. The following languages can all be handled by a DFA:
      \begin{itemize}
        \item $\set{ \epsilon }$
        \item $\Sigma^\star$
        \item For every $a \in \Sigma, \set{a}$
        \item For every $w \in \Sigma^\star, \set{w}$ (Note that in this case, $|w| + 2$ states are required.)
      \end{itemize}

      \subsubsection{Closure Operations}
        Is the family of languages that can be computed by a DFA closed under $\cup, \cap$, set difference, concatenation, $L^\star$, etc?
        \\ \\
        \textbf{Claim}: if each of $L_1, L_2$ can be computed by some DFA, then so can $L_1 \cap L_2, L_1 \cup L_2$, and $L_1 \backslash L_2$.

        \begin{proof}
          Let $A_1$ and $A_2$ be DFAs such that $L(A_1) = L_1$ and $L(A_2) = L_2$. Let's construct some DFA $A_3$ such that $L(A_3) = L_1 \cap L_2$.
          \\ \\
          The general idea is to run the two machines, $A_1$ and $A_2$, in parallel, and if $w \in F$ in both machines, accept $w$ for $L_1 \cap L_2$.
          \\ \\
          Given any two automatons $A_1 = (\Sigma, Q_1, q_0^1, \delta_1, F_1)$ and $A_2 = (\Sigma, Q_2, q_0^2, \delta_2, F_2)$, we define the \textbf{product automaton} as
          $$
            A_1 \times A_2 = (\Sigma, Q_1 \times Q_2, (q_0^1, q_0^2), \delta_{A_1 \times A_2}, F_{A_1 \times A_2})
          $$
          where $\Sigma$ is the same alphabet as defined previously, $Q_1 \times Q_2 = \set{ (p, q) : p \in Q_1, q \in Q_2 }$, and $\delta_{A_1 \times A_2}((p, q), a) = (\delta_1(p, a), \delta_2(q, a))$.
          \\ \\
          $F$ will be defined differently depending on which combination we wish to compute. For example:
          \begin{itemize}
            \item $F_{A_1 \cap A_2} = \set{ (p, q) : p \in F_1 \text{ and } q \in F_2 }$
            \item $F_{A_1 \cup A_2} = \set{ (p, q) : p \in F_1 \text{ or } q \in F_2 }$
            \item $F_{A_1 \backslash A_2} = \set{ (p, q) : p \in F_1 \text{ and } q \not \in F_2 }$
          \end{itemize}

          \textbf{Conclusion}: if $L_1$ and $L_2$ both have DFAs, then so do $L_1 \cap L_2, L_1 \cup L_2, L_1 \backslash L_2, L_1 \Delta L_2$, etc. (any boolean operation on sets). However, note that the product automaton does not tell us if a language is closed under $L^\star$ or concatenation.
          \\ \\
          Is it true that whenever $L$ has a DFA, then so does its complement, $L^C = \Sigma^\star \backslash L$? Yes, its DFA is $L_{\Sigma^\star \times L}$. More simply, let $A = (\Sigma, Q, q_0, \delta, F)$ be a DFA such that $L(A) = L$, then let $A^C = (\Sigma, Q, q_0, \delta, Q \backslash F)$. Then, $L(A^C) = L^C$.
          \\ \\
          Since in our definition of a DFA we required that for every state $q \in Q$ and every letter $a \in \Sigma$, $q$ has some outgoing edge labelled by $a$ (we are never stuck).
        \end{proof}
\end{document}
